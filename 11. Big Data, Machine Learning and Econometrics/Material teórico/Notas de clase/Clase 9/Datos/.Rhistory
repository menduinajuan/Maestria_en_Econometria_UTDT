library(fGarch)
#library(forecast)
library(gets)
#library(normtest)
library(openxlsx)
#library(rugarch)
library(tseries)
# Econometría de Series de Tiempo - Examen Final
# Juan Menduiña
#Limpiar la memoria#
ls()
rm(list = ls())
#Evitar notación científica en números decimales#
options(scipen = 999)
#Paquetes utilizados#
library(aTSA)
library(fGarch)
#library(forecast)
library(gets)
#library(normtest)
library(openxlsx)
#library(rugarch)
#library(tseries)
library(urca)
library(vars)
library(zoo)
base1 <- read.xlsx("G:/Mi Unidad/JM/Facultad de Ciencias Económicas (FCE)/Maestría en Economía/7. Econometría de Series de Tiempo/Examen/Datos/base1.xlsx")
################# kNN en R: https://cran.r-project.org/web/packages/FNN/FNN.pdf
# install.packages('FNN');
library(FNN)
###############################################################################
##### 1) Simulando los datos de entrenamiento:
f <- function(X){sin(2*X) + sqrt(X)}
X = seq(0,4*pi,length.out = 200)
set.seed(1) # Fijamos la semilla para que todos tengamos el mismo data set.
Y =  f(X) + rnorm(200)
par(mar=c(4,4,1,1))
plot(X,f(X), type = 'l',ylab='f(X)',
ylim = c(-3,6),bty='n', lwd = 3, lty = 1)
points(X,Y, pch = 20)
####################################################################
### Validation set approach ########################################
####################################################################
datos = cbind(X,Y)
set.seed(1)
id.train = sample(200,100, replace = FALSE) # que es id.train?
train = datos[ id.train, ] # <- indica que filas de Train selecciono para train.
dim(train)
head(train)
val  = datos[-id.train,]
dim(val)
k.par = c(1,5,10,20,50,80)
MSE = c() # Aquí guardo el error cuadrático medio fuera de la muestra.
for(i in 1:6){
kNNreg = knn.reg(train = as.matrix(train[,1]) ,
y = as.matrix(train[,2]),
test = as.matrix(val[,1]),
k = k.par[i])
pred = kNNreg$pred
MSE[i] = sum( (pred - val[,2])^2 ) / 100
print(i)
}
cbind(k.par, MSE)
which(MSE == min(MSE))
k.par[which(MSE == min(MSE))] # k-óptimo estimado por VC: Val-Set app.
plot(k.par, MSE, type = 'b', xlab = 'k', ylab = 'Estimación MSE',
ylim=c(0.8,2), lwd = 2, pch = 20)
View(f)
####################################################################
### LOOCV                   ########################################
####################################################################
MSE = c() # Aquí guardo el error cuadrático medio fuera de la muestra.
sd = c()
for(i in 1:6){
mse = c() # Aquí guardo el ecm sobre cada muestra de validación.
for(j in 1:200){
train = matrix(datos[ -j,], ncol = 2)
val   = matrix(datos[  j,], ncol = 2)
kNNreg = knn.reg(train = as.matrix(train[,1]) ,
y = as.matrix(train[,2]),
test = as.matrix(val[,1]),
k = k.par[i])
mse[j] = (kNNreg$pred - val[,2])^2
} # end for  en "j"
MSE[i] = mean(mse)
sd[i] = sd(mse)
print(i)} # end for en "i"
cbind(k.par, MSE, sd)
k.par[which(MSE == min(MSE))] # k = 10
points(k.par, MSE, type = 'b', col = 'red', lwd = 2, pch = 20)
####################################################################
### B-fold CV               ########################################
####################################################################
n = 200; B = 5
folds <- cut(seq(1,n),breaks=B,labels=FALSE)
folds # Indicador de cada uno de los folds
set.seed(321) # Permuto las observaciones en cada fold.
folds = folds[sample(200,200)]
folds # table(folds)
MSE = c()  # Aquí guardo el error cuadrático medio para cada valor de k.
se  = c()  # Aquí guardo el error estandard para cada valor de k.
for(i in 1:6){ # i recorre los valores del parámetro "k" (ver "k.par[i]" más abajo).
mse.b = c()      # Vector auxiliar en donde iré guardando el ecm para cada valor de k en cada fold de validación.
for(j in 1:B){ # j-recorre los folds
index.train = which(folds!=j) # selecciono observaciones que hacen de train.
index.val   = which(folds==j) # selecciono observaciones que hacen de validación.
train = matrix(datos[ index.train,], ncol = 2)
val   = matrix(datos[ index.val  ,], ncol = 2) # mirar esquema de la diapo 30.
kNNreg = knn.reg(train = as.matrix(train[,1]) ,
y = as.matrix(train[,2]),
test = as.matrix(val[,1]),
k = k.par[i]) # El primer bucle for va cambiando los valores de "k".
mse.b[j] = sum( (kNNreg$pred - val[,2])^2 ) / 40
}
MSE = c()  # Aquí guardo el error cuadrático medio para cada valor de k.
se  = c()  # Aquí guardo el error estandard para cada valor de k.
for(i in 1:6){ # i recorre los valores del parámetro "k" (ver "k.par[i]" más abajo).
mse.b = c()      # Vector auxiliar en donde iré guardando el ecm para cada valor de k en cada fold de validación.
for(j in 1:B){ # j-recorre los folds
index.train = which(folds!=j) # selecciono observaciones que hacen de train.
index.val   = which(folds==j) # selecciono observaciones que hacen de validación.
train = matrix(datos[ index.train,], ncol = 2)
val   = matrix(datos[ index.val  ,], ncol = 2) # mirar esquema de la diapo 30.
kNNreg = knn.reg(train = as.matrix(train[,1]) ,
y = as.matrix(train[,2]),
test = as.matrix(val[,1]),
k = k.par[i]) # El primer bucle for va cambiando los valores de "k".
mse.b[j] = sum( (kNNreg$pred - val[,2])^2 ) / 40
}
MSE[i] = mean(mse.b);
se[i]  = sd(mse.b);
print(i)
}
cbind(k.par, MSE, se)
k.par[which(MSE == min(MSE))] # k = 10
points(k.par,MSE ,type='b', col = 'blue', lwd = 2, pch = 20) #
################# kNN en R: https://cran.r-project.org/web/packages/FNN/FNN.pdf
# install.packages('FNN');
library(FNN)
###############################################################################
##### 1) Simulando los datos de entrenamiento:
f <- function(X){sin(2*X) + sqrt(X)}
X = seq(0,4*pi,length.out = 200)
set.seed(1) # Fijamos la semilla para que todos tengamos el mismo data set.
Y =  f(X) + rnorm(200)
par(mar=c(4,4,1,1))
plot(X,f(X), type = 'l',ylab='f(X)',
ylim = c(-3,6),bty='n', lwd = 3, lty = 1)
points(X,Y, pch = 20)
####################################################################
### Validation set approach ########################################
####################################################################
datos = cbind(X,Y)
set.seed(1)
id.train = sample(200,100, replace = FALSE) # que es id.train?
train = datos[ id.train, ] # <- indica que filas de Train selecciono para train.
dim(train)
head(train)
val  = datos[-id.train,]
dim(val)
k.par = c(1,5,10,20,50,80)
MSE = c() # Aquí guardo el error cuadrático medio fuera de la muestra.
for(i in 1:6){
kNNreg = knn.reg(train = as.matrix(train[,1]) ,
y = as.matrix(train[,2]),
test = as.matrix(val[,1]),
k = k.par[i])
pred = kNNreg$pred
MSE[i] = sum( (pred - val[,2])^2 ) / 100
print(i)
}
cbind(k.par, MSE)
which(MSE == min(MSE))
k.par[which(MSE == min(MSE))] # k-óptimo estimado por VC: Val-Set app.
plot(k.par, MSE, type = 'b', xlab = 'k', ylab = 'Estimación MSE',
ylim=c(0.8,2), lwd = 2, pch = 20)
# El valor estimado como adecuado para $k$ es 10.
################ End Validation-Set app.
####################################################################
### LOOCV                   ########################################
####################################################################
MSE = c() # Aquí guardo el error cuadrático medio fuera de la muestra.
sd = c()
for(i in 1:6){
mse = c() # Aquí guardo el ecm sobre cada muestra de validación.
for(j in 1:200){
train = matrix(datos[ -j,], ncol = 2)
val   = matrix(datos[  j,], ncol = 2)
kNNreg = knn.reg(train = as.matrix(train[,1]) ,
y = as.matrix(train[,2]),
test = as.matrix(val[,1]),
k = k.par[i])
mse[j] = (kNNreg$pred - val[,2])^2
} # end for  en "j"
MSE[i] = mean(mse)
sd[i] = sd(mse)
print(i)} # end for en "i"
cbind(k.par, MSE, sd)
k.par[which(MSE == min(MSE))] # k = 10
points(k.par, MSE, type = 'b', col = 'red', lwd = 2, pch = 20)
# El valor estimado como adecuado para $k$ es 10.
################ End LOOCV.
####################################################################
### B-fold CV               ########################################
####################################################################
n = 200; B = 5
folds <- cut(seq(1,n),breaks=B,labels=FALSE)
folds # Indicador de cada uno de los folds
set.seed(321) # Permuto las observaciones en cada fold.
folds = folds[sample(200,200)]
folds # table(folds)
MSE = c()  # Aquí guardo el error cuadrático medio para cada valor de k.
se  = c()  # Aquí guardo el error estandard para cada valor de k.
for(i in 1:6){ # i recorre los valores del parámetro "k" (ver "k.par[i]" más abajo).
mse.b = c()      # Vector auxiliar en donde iré guardando el ecm para cada valor de k en cada fold de validación.
for(j in 1:B){ # j-recorre los folds
index.train = which(folds!=j) # selecciono observaciones que hacen de train.
index.val   = which(folds==j) # selecciono observaciones que hacen de validación.
train = matrix(datos[ index.train,], ncol = 2)
val   = matrix(datos[ index.val  ,], ncol = 2) # mirar esquema de la diapo 30.
kNNreg = knn.reg(train = as.matrix(train[,1]) ,
y = as.matrix(train[,2]),
test = as.matrix(val[,1]),
k = k.par[i]) # El primer bucle for va cambiando los valores de "k".
mse.b[j] = sum( (kNNreg$pred - val[,2])^2 ) / 40
}
MSE[i] = mean(mse.b);
se[i]  = sd(mse.b);
print(i)
}
cbind(k.par, MSE, se)
k.par[which(MSE == min(MSE))] # k = 10
points(k.par,MSE ,type='b', col = 'blue', lwd = 2, pch = 20) #
################# kNN en R: https://cran.r-project.org/web/packages/FNN/FNN.pdf
# install.packages('FNN');
library(FNN)
###############################################################################
##### 1) Simulando los datos de entrenamiento:
f <- function(X){sin(2*X) + sqrt(X)}
X = seq(0,4*pi,length.out = 200)
set.seed(1) # Fijamos la semilla para que todos tengamos el mismo data set.
Y =  f(X) + rnorm(200)
par(mar=c(4,4,1,1))
plot(X,f(X), type = 'l',ylab='f(X)',
ylim = c(-3,6),bty='n', lwd = 3, lty = 1)
points(X,Y, pch = 20)
####################################################################
### Validation set approach ########################################
####################################################################
datos = cbind(X,Y)
set.seed(1)
id.train = sample(200,100, replace = FALSE) # que es id.train?
train = datos[ id.train, ] # <- indica que filas de Train selecciono para train.
dim(train)
head(train)
val  = datos[-id.train,]
dim(val)
k.par = c(1,5,10,20,50,80)
MSE = c() # Aquí guardo el error cuadrático medio fuera de la muestra.
for(i in 1:6){
kNNreg = knn.reg(train = as.matrix(train[,1]) ,
y = as.matrix(train[,2]),
test = as.matrix(val[,1]),
k = k.par[i])
pred = kNNreg$pred
MSE[i] = sum( (pred - val[,2])^2 ) / 100
print(i)
}
cbind(k.par, MSE)
which(MSE == min(MSE))
k.par[which(MSE == min(MSE))] # k-óptimo estimado por VC: Val-Set app.
plot(k.par, MSE, type = 'b', xlab = 'k', ylab = 'Estimación MSE',
ylim=c(0.8,2), lwd = 2, pch = 20)
# El valor estimado como adecuado para $k$ es 10.
################ End Validation-Set app.
####################################################################
### LOOCV                   ########################################
####################################################################
MSE = c() # Aquí guardo el error cuadrático medio fuera de la muestra.
sd = c()
for(i in 1:6){
mse = c() # Aquí guardo el ecm sobre cada muestra de validación.
for(j in 1:200){
train = matrix(datos[ -j,], ncol = 2)
val   = matrix(datos[  j,], ncol = 2)
kNNreg = knn.reg(train = as.matrix(train[,1]) ,
y = as.matrix(train[,2]),
test = as.matrix(val[,1]),
k = k.par[i])
mse[j] = (kNNreg$pred - val[,2])^2
} # end for  en "j"
MSE[i] = mean(mse)
sd[i] = sd(mse)
print(i)} # end for en "i"
cbind(k.par, MSE, sd)
k.par[which(MSE == min(MSE))] # k = 10
points(k.par, MSE, type = 'b', col = 'red', lwd = 2, pch = 20)
# El valor estimado como adecuado para $k$ es 10.
################ End LOOCV.
####################################################################
### B-fold CV               ########################################
####################################################################
n = 200; B = 5
folds <- cut(seq(1,n),breaks=B,labels=FALSE)
folds # Indicador de cada uno de los folds
set.seed(321) # Permuto las observaciones en cada fold.
folds = folds[sample(200,200)]
folds # table(folds)
MSE = c()  # Aquí guardo el error cuadrático medio para cada valor de k.
se  = c()  # Aquí guardo el error estandard para cada valor de k.
for(i in 1:6){ # i recorre los valores del parámetro "k" (ver "k.par[i]" más abajo).
mse.b = c()      # Vector auxiliar en donde iré guardando el ecm para cada valor de k en cada fold de validación.
for(j in 1:B){ # j-recorre los folds
index.train = which(folds!=j) # selecciono observaciones que hacen de train.
index.val   = which(folds==j) # selecciono observaciones que hacen de validación.
train = matrix(datos[ index.train,], ncol = 2)
val   = matrix(datos[ index.val  ,], ncol = 2) # mirar esquema de la diapo 30.
kNNreg = knn.reg(train = as.matrix(train[,1]) ,
y = as.matrix(train[,2]),
test = as.matrix(val[,1]),
k = k.par[i]) # El primer bucle for va cambiando los valores de "k".
mse.b[j] = sum( (kNNreg$pred - val[,2])^2 ) / 40
}
MSE[i] = mean(mse.b);
se[i]  = sd(mse.b);
print(i)
}
cbind(k.par, MSE, se)
k.par[which(MSE == min(MSE))] # k = 10
points(k.par,MSE ,type='b', col = 'blue', lwd = 2, pch = 20) #
################# kNN en R: https://cran.r-project.org/web/packages/FNN/FNN.pdf
# install.packages('FNN');
library(FNN)
czc
library(keras)
reticulate::use_condaenv(condaenv = "r-tensorflow")
#####Preparando los datos:
setwd('G:/Mi unidad/JM/Facultad de Ciencias Económicas (FCE)/Maestría en Econometría/11. Big Data, Machine Learning and Econometrics/Material teórico/Notas de clase/Clase 9/Datos')
X <- read.table(file = 'fashion-mnist.csv',sep =',', header = T)
dim(X)
head(X,1) # Ver labels en las slides (# 56). Similar al data set con dígitos.
################################################################################
plotFashion <- function(images){
op <- par(no.readonly=TRUE)
x <- ceiling(sqrt(length(images)))
par(mfrow=c(x, x), mar=c(.1, .1, .1, .1))
for (i in images){
m <- matrix(data.matrix(X[i,-1]), nrow=28, byrow=TRUE)
m <- apply(m, 2, rev)
image(t(m), col=grey.colors(255), axes=FALSE)
text(0.05, 0.2, col="red", cex=2.5, X[i, 1])
}
par(op)
}
x11(); plotFashion(1:9)
y = X[, 1] # Labels o etiquetas
X = X[,-1] / 255 # valor pixel normalizado en [0,1] (28x28) <- Es importante escalar los features para acelerar la convergencia del algoritmo con el que aprendemos los parámetros del modelo.
set.seed(1)
train.id = sample(30000,30000) # 30 mil imágenes en train y 30 mil en test.
x_train = as.matrix(X[ train.id, ]); dim(x_train)
train_labels = y[train.id]
x_test= as.matrix(X[-train.id, ])
test_labels = y[-train.id]
# Para pre-procesar las imágenes y aplicar filtros kernas
# necesita las imagenes en formato 'fila-columna' (como lo describimos en teoría):
x_train <- x_train %>% array_reshape(c(30000, 28, 28, 1)); dim(x_train) # 300002828 1
dim(x_train) # array de 30 mil imágenes de 28x28x1 (blanco y negro).
x_test <- x_test %>% array_reshape(c(30000, 28, 28, 1)) #idem al caso anterior.
# Especificando el modelo (arquitectura de la red convolucional profunda):
model <- keras_model_sequential()
model %>%
layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = 'relu',
input_shape = c(28, 28, 1), name = 'CapaConvolucion') %>% # CAPA de convolución + ReLu.
layer_max_pooling_2d(pool_size = c(2,2), name = 'CapaPooling') %>% # CAPA de pooling.
layer_flatten(name = 'CapaFlat') %>% # CAPA de 'vectorización' (aplastamiento).
layer_dense(units = 128, activation = 'relu', name = 'CapaOculta1') %>% # Capa oculta de neuronas (activacion relu).
layer_dropout(rate = 0.5) %>% # Tasa de dropout = 50% (regularización, en algún sentido es parecido a hacer "lasso").
layer_dense(units = 10, activation = 'softmax', name = 'CapaSalida') # Capa de salida (activacion softmax, ver apéndice).
summary(model)
# "Compilamos" el modelo:
model %>% compile(
loss = 'sparse_categorical_crossentropy',
optimizer = 'adam',
metrics = c('accuracy')
)
# Fiteamos el modelo:
history <- model %>% fit(x_train, train_labels, epochs = 10) # Con epochs controlamos la cantidad de recursiones.
# Evaluamos el modelo sobre el conjunto de test:
score <- model %>% evaluate(x_test, test_labels)
cat('Test loss:', score[1], "\n") # Valor de la cross--entropy (función de riesgo empírico) en el conjunto de test.
cat('Test accuracy:', score[2], "\n") # Acierto del 90% sobre test.
predictions <- model %>% predict(x_test)
dim(predictions) # Contiene las salidas de la red profunda.
head(round(predictions,3),3);
head(rowSums(predictions),5) # Activación softmax en la capa de salida (ver slide 56, apéndice).
which.max(predictions[1, ])
head(apply(predictions, 1, which.max), 3) # <- indica a que categoría se corresponde la probabilidad estimada más alta.
class_pred <- model %>% predict(x_test) %>% k_argmax() # Asigna a la clase más probable.
class_pred[1:4] # 0 = T-Shirt, 1 = Touser... etc
class_names = c('T-shirt/top','Trouser','Pullover',
'Dress','Coat','Sandal','Shirt',
'Sneaker','Bag','Ankle boot')
x11() # Tomamos las primeras 25 observaciones de Test
options(repr.plot.width=7, repr.plot.height=7)
par(mfcol=c(5,5))
par(mar=c(0, 0, 1.5, 0), xaxs='i', yaxs='i')
for (i in 1:25) {
img <- x_test[i, , ,1]
img <- t(apply(img, 2, rev))
# subtract 1 as labels go from 0 to 9
predicted_label <- which.max(predictions[i, ]) - 1
true_label <- test_labels[i]
if (predicted_label == true_label) {
color <- '#008800'
} else {
color <- '#bb0000'
}
image(1:28, 1:28, img, col = gray((0:255)/255), xaxt = 'n', yaxt = 'n',
main = paste0(class_names[predicted_label + 1], " (",
class_names[true_label + 1], ")"),
col.main = color)
}
rm(list=ls());dev.off()
#--------------- Pipeline para SSA (brexit data) ---------------#
require(ASSA) || install.packages('ASSA')
library(ASSA)
data("brexit") # https://ig.ft.com/sites/brexit-polling/
tail(brexit, 3) # Los datos estan ordenados de más viejo (arriba) a más nuevo (abajo)
head(brexit, 3) # Los datos estan ordenados de más viejo (arriba) a más nuevo (abajo)
##################
attach(brexit)
# Raw polldata (desde 2013 en adelante):
x11()
plot(date[1:266], leave[1:266], pch = 16, xlab = "Time (in years)",
ylab = "Percentage", ylim = c(0, 66), cex.lab = 1.4, cex.axis = 1.4,
cex = 1.4)
points(date[1:266], stay[1:266], pch = 16, col = "gray", cex = 1.4)
points(date[1:266], undecided[1:266], pch = 3, cex = 1.4)
raw.l <- tsframe(date, leave/100) # Los datos tienen que estar en formato "ASSA" (parecido a ts())
fit.l <- sst(raw.l, l = 100 , m = 5) # (l y m) son hiperparámetros sensibles
dim(fit.l$erc[[1]]) # Componentes fundamentales de la serie
fit.l$trendline # Versión "filtrada" (nowcasting) de la serie.
x11()
plot(fit.l, col = 'blue', ylab = 'leave', type = 'l', lwd = 2, ylim = c(0.2,0.65))
points(date, leave/100, pch = 20, lwd = 0.5) # Overfitting
fit.l <- sst(raw.l) # (l = 'automatic' y m = 'automatic')
x11()
plot(fit.l, col = 'blue', ylab = 'leave', type = 'l', lwd = 2, ylim = c(0.2,0.65))
points(date, leave/100, pch = 20, lwd = 0.5)
# Hiperparámetros seleccionados de forma automática
#(utilizando el test basado en el periodograma de los residuos, slide 17):
fit.l$l; fit.l$m
#### Otros outputs gráficos del paquete:
# Componentes elementales (ERC):
dim(fit.l$erc[[1]])
x11()# El fitting que produce el modelo es la suma de estas dos componentes.
plot(fit.l, options = list(type = "components", ncomp = 1:2),
col='red', type = 'l', ylab = '')
# Periodograma (y bandas del 95%) (ver algoritmo en slide 17)
x11(); par(mfrow=c(1,1), mar=c(4,2,1,1))
plot(fit.l, options = list(type = "cpgram"))
# Scree-plot (criterio alternativo para elegir la cantidad de compontes)
x11(); par(mfrow=c(1,1), mar=c(4,2,1,1))
plot(fit.l, options = list(type = "screeplot", ncomp = 1:8))
##### Fitting de las demás series (stay, undecided):
raw.s <- tsframe(date, stay/100)
fit.s <- sst(raw.s)
fit.s$l; fit.s$m # l = 137 y m = 2 para stay
raw.u <- tsframe(date, undecided/100)
fit.u <- sst(raw.u)
fit.u$l; fit.u$m # l = 137 y m = 1 para undecided
x11()
plot(date[1:266], leave[1:266], pch = 16, xlab = "Time (in years)",
ylab = "Percentage", ylim = c(0, 66), cex.lab = 1.4, cex.axis = 1.4,
cex = 1.4)
points(date[1:266], stay[1:266], pch = 16, col = "gray", cex = 1.4)
points(date[1:266], undecided[1:266], pch = 3, cex = 1.4)
lines(date[1:266], fit.l$trendline$y[-c(1:6)]*100, col = "blue", lwd = 3)
lines(date[1:266], fit.s$trendline$y[-c(1:6)]*100, col = "red", lwd = 3)
lines(date[1:266], fit.u$trendline$y[-c(1:6)]*100, col = "black", lwd = 3)
predict(fit.l, p = 5)$forecasts # basado en l = 137 y m = 2
predict(fit.s, p = 5)$forecasts # basado en l = 137 y m = 2
predict(fit.u, p = 5)$forecasts # basado en l = 137 y m = 1
# El modelo univariante no es consistente con la naturaleza composicional de los datos:
predict(fit.l, p = 1)$forecasts +predict(fit.s, p = 1)$forecasts + predict(fit.u, p = 1)$forecasts
y <- mtsframe(date, Y = brexit[, 1:3]/100) # Serie temporal multivariante
?msst ; ?msstc # Algunos de los modelos multivariantes implementados en el paquete.
fit <- msstc(y, vertical = TRUE) # tiene en cuenta la posible autocorrelación entre las series.
class(fit)
head(fit$trendlines$Y, 3)
head(rowSums(fit$trendlines$Y), 3) # Datos composicionales
fit$m; fit$l; fit$vertical
predict(fit, p = 3)$forecast
rowSums(predict(fit, p = 3)$forecast) # Las estimaciones y las prediciones 'suman 1'.
x11()
plot(date[1:266], leave[1:266], pch = 16, xlab = "Time (in years)",
ylab = "Percentage", ylim = c(0, 66), cex.lab = 1.4, cex.axis = 1.4,
cex = 1.4)
points(date[1:266], stay[1:266], pch = 16, col = "gray", cex = 1.4)
points(date[1:266], undecided[1:266], pch = 3, cex = 1.4)
lines(date[1:266], fit$trendlines$Y[-c(1:6),1]*100, col = "blue", lwd = 3)
lines(date[1:266], fit$trendlines$Y[-c(1:6),2]*100, col = "red", lwd = 3)
lines(date[1:266], fit$trendlines$Y[-c(1:6),3]*100, col = "black", lwd = 3)
#### Otros outputs gráficos del paquete:
# Componentes elementales (ERC):
dim(fit$erc[[1]]) #
x11()
plot(fit, options = list(type = "components", ncomp = 1:2))
# Periodogram (y bandas del 95%)
x11()
par(mfrow=c(1,3), mar=c(4,2,1,1))
plot(fit, options = list(type = "cpgrams"))
